{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrsferret/Machine-Learning-ITNPBD6-/blob/main/TFComputerVision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltsApv4RP_jN"
      },
      "source": [
        "# Building an Image Classifier Convolutional Neural Network in Keras with Tensorflow\n",
        "\n",
        "- Uses a small part of the Cifar10 dataset\n",
        "- Assumes you have downloaded the file `data_batch_1` from cifar (or the University of Stirling module webpage)\n",
        "- Uses Keras to build the CNN\n",
        "\n",
        "You can learn more about the Cifar10 data set here<br> https://www.cs.toronto.edu/~kriz/cifar.html<br>\n",
        "You do not need to do that to complete this workbook, however."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Uu-tH8JP_jQ"
      },
      "source": [
        "## Imports\n",
        "The data from Cifar10 is wrapped up in a pickle file, so we need the `pickle` library to unpack it. We also need numpy to hold the data and matplotlib if we want to look at the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcFb6QyHP_jR"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-VGWMbFP_jS"
      },
      "source": [
        "## The Data\n",
        "For this example, we are just using a small number of the Cifar images. They come in batches, so we will just use batch 1. You can download all the data from the Cifar web page, but if you are using this as part of a course at the University of Stirling, the two files you need should have been made available on your learning platform. They are:\n",
        "\n",
        "- data_batch_1\n",
        "- batches.meta\n",
        "\n",
        "If they are not in the same folder as this code on your computer, you will need to give their path in the unpickle calls below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7ZtboadP_jT"
      },
      "outputs": [],
      "source": [
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "imgs = unpickle('data_batch_1')\n",
        "meta_data_dict = unpickle(\"batches.meta\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utzsPhXmP_jU"
      },
      "source": [
        "## Now Let's Look at What We've Got\n",
        "Here we extract the data and the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHXv8bv7P_jU"
      },
      "outputs": [],
      "source": [
        "print(imgs.keys())\n",
        "print(meta_data_dict)\n",
        "labels = meta_data_dict[b'label_names']\n",
        "labels = [l.decode(\"utf-8\") for l in labels]\n",
        "print(labels)\n",
        "batch1 = imgs[b'data']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6JMYJFxP_jV"
      },
      "source": [
        "## Reshape the Arrays\n",
        "The data are in 1D arrays, so we reshape them to 32 x 32 arrays of pixel values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsNh3yA4P_jV"
      },
      "outputs": [],
      "source": [
        "batch1 = batch1.reshape((len(batch1), 3, 32, 32))\n",
        "batch1 = np.rollaxis(batch1, 1, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJhUgVzmP_jW"
      },
      "source": [
        "## Plot an Image\n",
        "We can see what one of the images looks like by plotting it. Change the index `[0]` to another number to see different examples, or plot a few in a loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxHu7O14P_jW"
      },
      "outputs": [],
      "source": [
        "plt.imshow(batch1[0])\n",
        "plt.show()\n",
        "label_ix = imgs[b'labels'][0]\n",
        "print(labels[label_ix])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG14cVURP_jX"
      },
      "source": [
        "## Finally, Tensorflow\n",
        "No we import Tensorflow and the parts of Keras that we will need. We also need the label encoder from scikit-learn to transform the labels to integers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1rYRrMlP_jX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Limit memory usage for GPU\n",
        "# Leave commented unless you know what you are doing and have TFGPU installed\n",
        "#import os\n",
        "#os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
        "#print(tf.__version__)\n",
        "\n",
        "x = batch1.astype('float32')\n",
        "y = imgs[b'labels']\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mwEkvANP_jX"
      },
      "source": [
        "## Build the model\n",
        "This is where you can experiment with different layers. You can see the basic pattern: Convolution, Pooling (repeat a few times), Dense, then output. We use softmax at the output to force the probabilities across the classes to sum to one.\n",
        "\n",
        "`SparseCategoricalCrossentropy` loss converts the integer label index values in `y` to one-hot encoded targets and applies the Cross Entropy cost function.\n",
        "\n",
        "Try different numbers of epochs (training cycles) to see how long the network needs to train before it stops improving.\n",
        "\n",
        "Try changing the number of filters at each convolution level. Can you get away with fewer than 64 at the last level? What if you use more in the first one instead?\n",
        "\n",
        "You can also try different activation functions ('sigmoid' for example) and add or remove layers to see how that effects the quality of the learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "la7XmsubP_jY"
      },
      "outputs": [],
      "source": [
        "# Build model\n",
        "\n",
        "# Begin the sequence of the model building\n",
        "model = Sequential()\n",
        "\n",
        "# First layer takes an input of 32 x 32 pixels by 3 colours with input_shape=(32, 32, 3)\n",
        "model.add(layers.Conv2D(5, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "# It has 5 three by 3 filters and uses a relu activation\n",
        "\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten()) # Flatten all the convolution layers into a single layer\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "# fit the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x, y, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0TmOR5CP_jY"
      },
      "source": [
        "## Plot the Accuracy by Epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTvAlDVGP_jY"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPUpO50UP_jY"
      },
      "source": [
        "## Make a Classification\n",
        "Change `test_img_ix` to choose different images from the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzEkkuZpP_jZ"
      },
      "outputs": [],
      "source": [
        "test_img_ix = 20\n",
        "plt.imshow(batch1[test_img_ix])\n",
        "plt.show()\n",
        "label_ix = imgs[b'labels'][test_img_ix]\n",
        "print(\"Label = \", labels[label_ix])\n",
        "class_scores = model.predict(x[test_img_ix:test_img_ix+1])\n",
        "best = np.argmax(class_scores)\n",
        "print(\"Classification =\", labels[best])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2tpkPC4P_jZ"
      },
      "source": [
        "## Plot the Probabilities\n",
        "Plot the probability of the image belonging to each possible class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7F9uj_0P_ja"
      },
      "outputs": [],
      "source": [
        "plt.bar(range(10), class_scores[0])\n",
        "plt.xticks(range(10), labels)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTj_pCXAP_ja"
      },
      "source": [
        "## Advanced Stuff Below!\n",
        "Finally, we examine the model to understand its structure. Use `model.summary()` to see the overall structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QA5FjFtKP_ja"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
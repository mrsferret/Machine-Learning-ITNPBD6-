{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrsferret/Machine-Learning-ITNPBD6-/blob/main/ExerciseSession2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaSFPty-lIht"
      },
      "source": [
        "# Splitting Your Data\n",
        "In this exercise, we'll load the same motor premiums data as you did in your last exercise with Python.\n",
        "\n",
        "In practice, what should happen is to do data cleaning after splitting training/test data. The reasoning behind this is that any data cleaning is part of the pipeline: it can influence the model accuracy too. Once you've decided the cleaning steps, you'd then (possibly) apply them to test data too. More discussion on this will follow in later weeks.\n",
        "\n",
        "Here we'll look at how we can split the data into train/validation/test sets and how to use cross-fold validation. Cleaning steps are added after the train/test split.\n",
        "\n",
        "(remember, click on a cell, then control+enter will run it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zjO96WslIhu",
        "outputId": "67d4e557-ab3b-43ef-a5f4-52589fb194e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          ID  Age Gender LicenceCountry  Yrs DL  Points  NCD  Engine cc  \\\n",
            "0  B69193007   52      M             UK      16       0    0       1200   \n",
            "1  B58763002   46      F             UK      22       8    1       1400   \n",
            "2  A57010377   59      F             UK       9       0    0       1400   \n",
            "3  B61470950   62      M             UK      35       0    0       1400   \n",
            "4  B43586226   59      F             UK       3       0    4       1400   \n",
            "\n",
            "   Ins Group  Stored  Car Age  Premium  \n",
            "0          4  Garage        2   195.32  \n",
            "1          2  Garage        7   225.09  \n",
            "2          5  Garage       14   201.08  \n",
            "3          4       0       12   211.76  \n",
            "4          5    Road       13   251.49  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# load the data...\n",
        "# remember to change this path if you've saved the data somewhere else\n",
        "df=pd.read_csv(\"MotorPremiums.csv\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2twcHrIlIhv"
      },
      "source": [
        "# Train / Test split\n",
        "If you've also completed this exercise in Orange, we're now replicating what we did with Data Sampler.\n",
        "\n",
        "First, we separate into X (the input features) and y (the target).\n",
        "\n",
        "Then splitting is really easy! We use train_test_split(); test_size is the fraction of the data that will form your test set; random_state initialises the random number generator so if you rerun it the split will be the same (change the number for a different split)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYW3eG91lIhv",
        "outputId": "6735410a-97e3-4c04-db50-ee8c2bda9026"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          ID  Age Gender LicenceCountry  Yrs DL  Points  NCD  Engine cc  \\\n",
            "0  B69193007   52      M             UK      16       0    0       1200   \n",
            "1  B58763002   46      F             UK      22       8    1       1400   \n",
            "2  A57010377   59      F             UK       9       0    0       1400   \n",
            "3  B61470950   62      M             UK      35       0    0       1400   \n",
            "4  B43586226   59      F             UK       3       0    4       1400   \n",
            "\n",
            "   Ins Group  Stored  Car Age  \n",
            "0          4  Garage        2  \n",
            "1          2  Garage        7  \n",
            "2          5  Garage       14  \n",
            "3          4       0       12  \n",
            "4          5    Road       13  \n",
            "0    195.32\n",
            "1    225.09\n",
            "2    201.08\n",
            "3    211.76\n",
            "4    251.49\n",
            "Name: Premium, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# set features and targets\n",
        "targetName=\"Premium\"\n",
        "#===================================================================\n",
        "# Split the data into 2 separate files ie. target and features\n",
        "#===================================================================\n",
        "# df.columns != targetName creates a boolean array where each element is True if the corresponding column name is not equal to\n",
        "# targetName (\"Premium\"), and False otherwise.\n",
        "# df.columns[df.columns != targetName] uses this boolean array to filter out the column names that are not equal to targetName.\n",
        "# This results in an Index object containing only the names of the feature columns.\n",
        "allFeatureNames=df.columns[df.columns != targetName]\n",
        "X = df[allFeatureNames]\n",
        "y = df[targetName]\n",
        "print(X.head())\n",
        "print(y.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cv8P-HA3lIhv"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets:\n",
        "\n",
        "# train_test_split(X, y, test_size=0.2, random_state=402):\n",
        "# X: The feature matrix.\n",
        "# y: The target vector.\n",
        "# test_size=0.2: Specifies the proportion of the dataset to include in the test split. Here, 20% of the data\n",
        "# will be used for testing, and the remaining 80% will be used for training.\n",
        "# random_state=402: Sets the seed for the random number generator. This ensures that the split is reproducible,\n",
        "# meaning the same split will be obtained every time you run the code with this seed.\n",
        "\n",
        "# random_state=402: Sets the seed for the random number generator. This ensures that the split is reproducible,\n",
        "# meaning the same split will be obtained every time you run the code with this seed.\n",
        "# test_size=0.2 means that 20% of the data will be used to testing and 80% for training\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=402)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hw5-hOQlIhw"
      },
      "source": [
        "We have now split the data, at random, into two sets. X_train and y_train are the training data, and should contain 3509 data points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLoIsx9llIhw",
        "outputId": "03d4189f-ed3a-482a-c722-748b15c78663"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>LicenceCountry</th>\n",
              "      <th>Yrs DL</th>\n",
              "      <th>Points</th>\n",
              "      <th>NCD</th>\n",
              "      <th>Engine cc</th>\n",
              "      <th>Ins Group</th>\n",
              "      <th>Stored</th>\n",
              "      <th>Car Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3942</th>\n",
              "      <td>B11376082</td>\n",
              "      <td>35</td>\n",
              "      <td>M</td>\n",
              "      <td>UK</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1200</td>\n",
              "      <td>4</td>\n",
              "      <td>Road</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>B39004071</td>\n",
              "      <td>53</td>\n",
              "      <td>M</td>\n",
              "      <td>UK</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1200</td>\n",
              "      <td>3</td>\n",
              "      <td>Garage</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2165</th>\n",
              "      <td>B520403</td>\n",
              "      <td>55</td>\n",
              "      <td>M</td>\n",
              "      <td>UK</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1200</td>\n",
              "      <td>3</td>\n",
              "      <td>Garage</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2171</th>\n",
              "      <td>A51648972</td>\n",
              "      <td>61</td>\n",
              "      <td>M</td>\n",
              "      <td>UK</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1400</td>\n",
              "      <td>6</td>\n",
              "      <td>Garage</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1135</th>\n",
              "      <td>B45810673</td>\n",
              "      <td>18</td>\n",
              "      <td>F</td>\n",
              "      <td>UK</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1200</td>\n",
              "      <td>4</td>\n",
              "      <td>Garage</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2469</th>\n",
              "      <td>A36517462</td>\n",
              "      <td>50</td>\n",
              "      <td>M</td>\n",
              "      <td>UK</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1400</td>\n",
              "      <td>6</td>\n",
              "      <td>Garage</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1807</th>\n",
              "      <td>A65813411</td>\n",
              "      <td>36</td>\n",
              "      <td>F</td>\n",
              "      <td>UK</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1200</td>\n",
              "      <td>2</td>\n",
              "      <td>Road</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014</th>\n",
              "      <td>A96543980</td>\n",
              "      <td>75</td>\n",
              "      <td>F</td>\n",
              "      <td>UK</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1800</td>\n",
              "      <td>3</td>\n",
              "      <td>Garage</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1226</th>\n",
              "      <td>B66545713</td>\n",
              "      <td>78</td>\n",
              "      <td>M</td>\n",
              "      <td>UK</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1400</td>\n",
              "      <td>3</td>\n",
              "      <td>Road</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>A49764633</td>\n",
              "      <td>31</td>\n",
              "      <td>F</td>\n",
              "      <td>UK</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1200</td>\n",
              "      <td>5</td>\n",
              "      <td>Road</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3509 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             ID  Age Gender LicenceCountry  Yrs DL  Points  NCD  Engine cc  \\\n",
              "3942  B11376082   35      M             UK       7       4    1       1200   \n",
              "519   B39004071   53      M             UK      35       0    3       1200   \n",
              "2165    B520403   55      M             UK      16       0    3       1200   \n",
              "2171  A51648972   61      M             UK      39       0    4       1400   \n",
              "1135  B45810673   18      F             UK       1       0    3       1200   \n",
              "...         ...  ...    ...            ...     ...     ...  ...        ...   \n",
              "2469  A36517462   50      M             UK      11       0    0       1400   \n",
              "1807  A65813411   36      F             UK      12       0    2       1200   \n",
              "2014  A96543980   75      F             UK      12       0    1       1800   \n",
              "1226  B66545713   78      M             UK      48       0    1       1400   \n",
              "389   A49764633   31      F             UK       9       0    1       1200   \n",
              "\n",
              "      Ins Group  Stored  Car Age  \n",
              "3942          4    Road       15  \n",
              "519           3  Garage        1  \n",
              "2165          3  Garage        3  \n",
              "2171          6  Garage        3  \n",
              "1135          4  Garage        1  \n",
              "...         ...     ...      ...  \n",
              "2469          6  Garage       10  \n",
              "1807          2    Road        1  \n",
              "2014          3  Garage        1  \n",
              "1226          3    Road        1  \n",
              "389           5    Road        1  \n",
              "\n",
              "[3509 rows x 11 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebMuklwelIhw",
        "outputId": "60cb4483-7655-4a8b-c2a5-daa7a6d9cc74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3942    239.28\n",
              "519     227.10\n",
              "2165    222.74\n",
              "2171    250.71\n",
              "1135    189.86\n",
              "         ...  \n",
              "2469    204.59\n",
              "1807    216.04\n",
              "2014    199.35\n",
              "1226    233.49\n",
              "389     214.76\n",
              "Name: Premium, Length: 3509, dtype: float64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9JPo3P9lIhw"
      },
      "source": [
        "We repeat the same process to produce a validation set as well..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PwgWJR7lIhw"
      },
      "outputs": [],
      "source": [
        "# we now further split X_train and y_train randomly to produce a validation set X_validation and y_validation\n",
        "\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_ieJFgXlIhw"
      },
      "source": [
        "We now have X_train, X_validation, and X_test, with the \"y_\" equivalents. We now start to develop our pipeline. For now, that means we do the same data cleaning we did in week 1..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBOrDC27lIhw"
      },
      "source": [
        "This code snippet is performing data cleaning and preprocessing on the training dataset for a machine learning model. Let's break down each part of the code step by step:\n",
        "\n",
        "### Step-by-Step Explanaon - from chatGon\n",
        "\n",
        "#### 1. Filtering the Rows\n",
        "\n",
        "```python\n",
        "# choose the rows we want to keep\n",
        "# ie. where LicenceCountry = \"UK\" and Stored not 0\n",
        "X_train_cleaned = X_train[(X_train.LicenceCountry==\"UK\") & (X_train.Stored!=\"0\")]\n",
        "y_train_cleaned = y_train[(X_train.LicenceCountry==\"UK\") & (X_train.Stored!=\"0\")] # remove the same rows from the target\n",
        "```\n",
        "\n",
        "- **Filtering Criteria**: The code selects rows where the `LicenceCountry` column is \"UK\" and the `Stored` column is not \"0\".\n",
        "- **`X_train_cleaned`**: This DataFrame contains the filtered rows of `X_train`.\n",
        "- **`y_train_cleaned`**: This Series contains the corresponding rows of `y_train` that match the filtering criteria applied to `X_train`.\n",
        "\n",
        "#### 2. Resetting the Index\n",
        "\n",
        "```python\n",
        "# this is needed so the row numbers are still in sequence\n",
        "X_train_cleaned = X_train_cleaned.reset_index(drop=True)\n",
        "y_train_cleaned = y_train_cleaned.reset_index(drop=True)\n",
        "```\n",
        "\n",
        "- **Purpose**: After filtering, the index might not be in sequence. `reset_index(drop=True)` resets the index of both `X_train_cleaned` and `y_train_cleaned` to ensure the row numbers are sequential and drop the old index.\n",
        "\n",
        "#### 3. Selecting Specific Features\n",
        "\n",
        "```python\n",
        "# define the list of features to keep\n",
        "selected_features = ['Age','Gender','Yrs DL','Points','NCD','Engine cc',\n",
        "                     'Ins Group','Stored','Car Age']\n",
        "\n",
        "# update the data frame\n",
        "X_train_cleaned = X_train_cleaned[selected_features]\n",
        "```\n",
        "\n",
        "- **`selected_features`**: A list of column names that are to be kept in the cleaned dataset.\n",
        "- **Updating `X_train_cleaned`**: The DataFrame `X_train_cleaned` is updated to only include the columns specified in `selected_features`.\n",
        "\n",
        "#### 4. Mapping Values in the 'Gender' Column\n",
        "\n",
        "```python\n",
        "# Map 'Female' and 'Male' F and M\n",
        "X_train_cleaned['Gender'] = X_train_cleaned['Gender'].replace({'Female':'F','Male':'M'})\n",
        "```\n",
        "\n",
        "- **Purpose**: This line replaces the values in the `Gender` column. \"Female\" is replaced with \"F\" and \"Male\" is replaced with \"M\".\n",
        "\n",
        "### Summary\n",
        "\n",
        "1. **Filtering Data**: The code filters rows in `X_train` where `LicenceCountry` is \"UK\" and `Stored` is not \"0\". Corresponding rows in `y_train` are also filtered.\n",
        "2. **Resetting Index**: The index of the filtered DataFrames `X_train_cleaned` and `y_train_cleaned` is reset to ensure sequential row numbers.\n",
        "3. **Selecting Features**: Only specific columns (features) are retained in `X_train_cleaned`.\n",
        "4. **Mapping Values**: The `Gender` column values are mapped from \"Female\" to \"F\" and \"Male\" to \"M\".\n",
        "\n",
        "This preprocessing step is crucial to prepare the dataset for training a machine learning model by ensuring the data is clean, relevant, and in a consistent format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNRIKvH5lIhx"
      },
      "outputs": [],
      "source": [
        "# choose the rows we want to keep\n",
        "# ie. where LicenceCountry = \"UK\" and Stored not 0\n",
        "X_train_cleaned = X_train[(X_train.LicenceCountry==\"UK\") & (X_train.Stored!=\"0\")]\n",
        "y_train_cleaned = y_train[(X_train.LicenceCountry==\"UK\") & (X_train.Stored!=\"0\")] # remove the same rows from the target\n",
        "\n",
        "# this is needed so the row numbers are still in sequence\n",
        "X_train_cleaned = X_train_cleaned.reset_index(drop=True)\n",
        "y_train_cleaned = y_train_cleaned.reset_index(drop=True)\n",
        "\n",
        "# define the list of features to keep\n",
        "selected_features = ['Age','Gender','Yrs DL','Points','NCD','Engine cc',\n",
        "                     'Ins Group','Stored','Car Age']\n",
        "\n",
        "# update the data frame\n",
        "X_train_cleaned = X_train_cleaned[selected_features]\n",
        "\n",
        "# Map 'Female' and 'Male' F and M\n",
        "X_train_cleaned['Gender'] = X_train_cleaned['Gender'].replace({'Female':'F','Male':'M'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjsgqN6WlIhx"
      },
      "source": [
        "Now, encode the categorical variables.\n",
        "\n",
        "This happens automatically in Orange: the models will only accept numbers as inputs, so we need to \"encode\" categorical variables, converting them into numbers. We used get_dummies() to do this last time, but now we're working on train/test sets separately we will want to be able to create the same columns on both; for that we'll use the OneHotEncoder that comes with sklearn. Doing it this way lets us remember the columns from the training set to use on the test set (or in deployment) later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deZJKR0flIhx"
      },
      "source": [
        "This code demonstrates how to use the `OneHotEncoder` from the `sklearn.preprocessing` module to encode categorical variables into a format suitable for machine learning algorithms. Let's go through the steps:\n",
        "\n",
        "### Step-by-Step Explanation - from chatGPT\n",
        "\n",
        "#### 1. Importing the Necessary Modules\n",
        "\n",
        "```python\n",
        "from numpy import asarray\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "```\n",
        "- **`asarray`**: This function from the NumPy library converts the input into an array.\n",
        "- **`OneHotEncoder`**: This class from scikit-learn is used for converting categorical data into a one-hot encoded format.\n",
        "\n",
        "#### 2. Creating the Example List\n",
        "\n",
        "```python\n",
        "# example_list = asarray([['apple'], ['orange'], ['pear'], ['apple']])\n",
        "```\n",
        "\n",
        "- **Example List**: A NumPy array is created with a list of categorical values (fruits in this case): \"apple\", \"orange\", \"pear\", and \"apple\" again.\n",
        "\n",
        "#### 3. Instantiating the OneHotEncoder\n",
        "\n",
        "```python\n",
        "# make a new OneHotEncoder to do the work for us...\n",
        "# (\"sparse\" makes the output more condensed for efficiency, but harder to read, so we'll disable that)\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "```\n",
        "\n",
        "- **OneHotEncoder Object**: An instance of `OneHotEncoder` is created with `sparse=False`.\n",
        "  - **`sparse_output=False`**: This ensures that the output will be a dense array, which is easier to read for demonstration purposes. If `sparse_output=True`, the output will be a sparse matrix which is more memory efficient.\n",
        "\n",
        "#### 4. Fitting the Encoder\n",
        "\n",
        "```python\n",
        "# fit() works out which columns to make and stores them in \"enc\"\n",
        "enc.fit(example_list)\n",
        "```\n",
        "\n",
        "- **`fit` Method**: This method analyzes the input data (`example_list`) and determines the unique categories within it. It then prepares the encoder to transform the data into a one-hot encoded format.\n",
        "  - **Storing Columns**: The `fit` method identifies unique categories (\"apple\", \"orange\", and \"pear\") and prepares to create one-hot encoded columns for each category.\n",
        "\n",
        "### Summary\n",
        "\n",
        "Here's a quick summary of what the code does:\n",
        "\n",
        "1. **Import Modules**: Import `asarray` from NumPy and `OneHotEncoder` from scikit-learn.\n",
        "2. **Create Example List**: Define a list of categorical values (fruits) and convert it into a NumPy array.\n",
        "3. **Instantiate OneHotEncoder**: Create an instance of `OneHotEncoder` with `sparse=False` to get a dense output.\n",
        "4. **Fit the Encoder**: Use the `fit` method on the `example_list` to learn the unique categories and prepare for one-hot encoding.\n",
        "\n",
        "### What is One-Hot Encoding?\n",
        "\n",
        "One-hot encoding is a process of converting categorical variables into a binary matrix representation. Each category becomes a column, and rows have binary values (0 or 1) indicating the presence of each category. For example:\n",
        "\n",
        "- Original Data: `[['apple'], ['orange'], ['pear'], ['apple']]`\n",
        "- One-Hot Encoded Data:\n",
        "  ```\n",
        "  [[1, 0, 0],\n",
        "   [0, 1, 0],\n",
        "   [0, 0, 1],\n",
        "   [1, 0, 0]]\n",
        "  ```\n",
        "\n",
        "In this encoding, each unique category gets its own column. For example, \"apple\" is represented as `[1, 0, 0]`, \"orange\" as `[0, 1, 0]`, and \"pear\" as `[0, 0, 1]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROdwUJp0lIhx",
        "outputId": "825a6ab2-0dde-47fb-e7e1-a4b2528d0220"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(sparse_output=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse_output=False)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "OneHotEncoder(sparse_output=False)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# As an example of how OneHotEncoder works, here is a list of values for a categorical variable:\n",
        "# (this is actually a grid/table, with only one column)\n",
        "# example of a dummy variable encoding\n",
        "from numpy import asarray\n",
        "#data = asarray([['red'], ['green'], ['blue']])\n",
        "example_list = asarray([['apple'], ['orange'], ['pear'], ['apple']])\n",
        "\n",
        "# make a new OneHotEncoder to do the work for us...\n",
        "# (\"sparse\" makes the output more condensed for efficiency, but harder to read, so we'll disable that)\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# fit() works out which columns to make and stores them in \"enc\"\n",
        "enc.fit(example_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loPbS9i-lIhx",
        "outputId": "3960371e-34c5-4d10-b85b-2f77ed0cb871"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# transform() then makes those columns in the data set we provide\n",
        "transformed_data = enc.transform(example_list)\n",
        "\n",
        "# you should see four rows, corresponding to the four data points in the original example_list\n",
        "# there are three columns, one for each of apple/orange/pear\n",
        "# each row has a 1 to show which fruit was in that position in the list\n",
        "print(transformed_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmuNCpOllIhx"
      },
      "source": [
        "At the same time, we can normalise the numerical variables to the range 0..1 using a MinMaxScaler, which is used in a similar way. These two processing steps can be combined into one processing routine using ColumnTransformer..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0v887uZQlIhx",
        "outputId": "c51638a6-1ed1-41e1-a5d3-2e919b76dc23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Age', 'Yrs DL', 'Points', 'NCD', 'Engine cc', 'Ins Group', 'Car Age'], dtype='object')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# First, determine categorical and numerical features\n",
        "# we can do that automatically looking for the column data types like this:\n",
        "numerical_ix = X_train_cleaned.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_ix = X_train_cleaned.select_dtypes(include=['object', 'bool']).columns\n",
        "\n",
        "# this now contains the names of the numerical variables:\n",
        "numerical_ix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sWfcJYolIhy",
        "outputId": "f4f345bb-d510-41a8-8432-b84592b04884"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Gender', 'Stored'], dtype='object')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ...and similar for the categorical:\n",
        "categorical_ix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bUlPKBXlIhy",
        "outputId": "0ce91840-8f55-448d-9caa-d5e92fb55e76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('cat', OneHotEncoder(drop='first', handle_unknown='infrequent_if_exist'), Index(['Gender', 'Stored'], dtype='object')), ('num', MinMaxScaler(), Index(['Age', 'Yrs DL', 'Points', 'NCD', 'Engine cc', 'Ins Group', 'Car Age'], dtype='object'))]\n",
            "[[0.         0.         1.         ... 0.         0.66666667 0.        ]\n",
            " [1.         1.         0.         ... 0.         0.66666667 0.26315789]\n",
            " [0.         1.         0.         ... 0.07692308 0.33333333 0.        ]\n",
            " ...\n",
            " [0.         1.         0.         ... 0.         0.66666667 0.05263158]\n",
            " [1.         0.         1.         ... 0.07692308 0.16666667 0.        ]\n",
            " [1.         0.         1.         ... 0.         0.5        0.        ]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# define the data preparation for the columns\n",
        "#\n",
        "# categorical columns will have a one hot encoder applied\n",
        "#   (note - we also set this to drop the first \"dummy\" column, similer to what we did last week; we have also\n",
        "#    told it how to handle unknown values, those that don't appear in the training data but do appear in validation\n",
        "#    or testing. 'infrequent_if_exist' assigns any unknown values to a separate category)\n",
        "#\n",
        "# numerical columns will be normalised\n",
        "#\n",
        "# each processing step also includes the list of columns that it will be applied to\n",
        "t = [('cat', OneHotEncoder(drop='first', handle_unknown='infrequent_if_exist'), categorical_ix), ('num', MinMaxScaler(), numerical_ix)]\n",
        "col_transform = ColumnTransformer(transformers=t)\n",
        "\n",
        "print(t)\n",
        "\n",
        "\n",
        "# fit() works out which columns to make and stores them in \"enc\"\n",
        "col_transform.fit(X_train_cleaned)\n",
        "\n",
        "# transform() then makes those columns in the data set we provide\n",
        "X_train_encoded = col_transform.transform(X_train_cleaned)\n",
        "\n",
        "# X_train_encoded will now be a numpy array, which can be used for training\n",
        "# the columns in this are the raw data\n",
        "print(X_train_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddU2Lu4BlIhy"
      },
      "source": [
        "We can then use the training data to train a model and use that model for doing predictions, like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUHaaVfWlIhy",
        "outputId": "73394134-3eb4-43ea-d9de-03b83044b61a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLPRegressor(alpha=0.001, hidden_layer_sizes=10, learning_rate_init=0.01,\n",
            "             max_iter=1000, random_state=1)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(alpha=0.001, hidden_layer_sizes=10, learning_rate_init=0.01,\n",
              "             max_iter=1000, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(alpha=0.001, hidden_layer_sizes=10, learning_rate_init=0.01,\n",
              "             max_iter=1000, random_state=1)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "MLPRegressor(alpha=0.001, hidden_layer_sizes=10, learning_rate_init=0.01,\n",
              "             max_iter=1000, random_state=1)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# make a new model - MLPRegressor is an artificial neural network\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "mlp_model = MLPRegressor(hidden_layer_sizes=(10), alpha=0.001, batch_size='auto',\n",
        "    learning_rate='constant', learning_rate_init=0.01, max_iter=1000, random_state=1)\n",
        "\n",
        "print(mlp_model)\n",
        "\n",
        "# train the model on (or fit the model to) our training data\n",
        "mlp_model.fit(X_train_encoded, y_train_cleaned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q4CcH6elIhy"
      },
      "source": [
        "Well done, you've just made your first model in scikit learn! We can now apply this model to unseen data to make some predictions. We'll use the validation set we separated out above for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EIpfi22lIhy"
      },
      "outputs": [],
      "source": [
        "# first, apply the same column transformations to the validation data...\n",
        "X_validation_transformed = col_transform.transform(X_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyvE3V-blIhy",
        "outputId": "55101293-6fef-4e5e-cf72-827784f1ea74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18.69373788890384\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Predictions')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# make some predictions using the model\n",
        "# store the predictions in y_pred\n",
        "y_pred = mlp_model.predict(X_validation_transformed)\n",
        "\n",
        "# how do the predictions compare to the true values?\n",
        "# print mean square error\n",
        "from sklearn import metrics\n",
        "print(metrics.mean_squared_error(y_validation, y_pred))\n",
        "\n",
        "# and a scatter plot\n",
        "from matplotlib import pyplot as plt\n",
        "plt.scatter(y_validation, y_pred)\n",
        "plt.xlabel(\"True Values\")\n",
        "plt.ylabel(\"Predictions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsztuyjBlIhy"
      },
      "source": [
        "# Cross-fold validation\n",
        "As in Orange, sklearn makes it easy to do cross-fold validation. By default, the built-in tool for this calls the `score` function of the model to measure model quality on each fold; `score()` works differently per model but the documentation will tell you that for an `MLPRegressor` it's the R^2 value, which would be 1.0 for a perfect model. If you want to use a different measure like mean square error you can specify which one you want from the list [here](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter).\n",
        "\n",
        "Here's how to perform the cross-fold validation, using 5 folds of our training set. We get a list of scores back in which each element is the score for one fold. We usually aggregate these (e.g. take the average) to get one overall score. You'll see the scores are negative: this is deliberate, and is so a \"bigger\" score (smaller error) is \"better\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "UR9emT-UlIhy",
        "outputId": "8f27b57d-3793-4222-94b6-04c8df5ee6d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-19.30991429 -18.63603471 -20.86669768 -21.72356501 -20.18491094]\n",
            "-20.144224523434428\n"
          ]
        }
      ],
      "source": [
        "# we'll reuse our training data from before. In practice we'd skip the extra split to training/validation sets.\n",
        "\n",
        "# compute scores for the 5 folds...\n",
        "# remember, this makes 5 seperate models, and tests them each on a different 0.2 of the data set.\n",
        "# the scores for these tests are returned in a list.\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(mlp_model, X_train_encoded, y_train_cleaned, cv=5, scoring='neg_mean_squared_error')\n",
        "print(scores)\n",
        "print(scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k34UwQwtlIhz"
      },
      "source": [
        "To interpret the results of the cross-validation, let's break down the output and what it signifies:\n",
        "\n",
        "### Output\n",
        "```\n",
        "[-19.30991429 -18.63603471 -20.86669768 -21.72356501 -20.18491094]\n",
        "-20.144224523434428\n",
        "```\n",
        "\n",
        "### Interpretation\n",
        "\n",
        "1. **Scores for Each Fold:**\n",
        "   ```python\n",
        "   [-19.30991429 -18.63603471 -20.86669768 -21.72356501 -20.18491094]\n",
        "   ```\n",
        "   - These values represent the negative mean squared error (MSE) for each of the 5 folds in the cross-validation process.\n",
        "   - The values are negative because we used `neg_mean_squared_error` as the scoring metric. This function returns the negative of the MSE values.\n",
        "\n",
        "2. **Understanding Each Fold's Score:**\n",
        "   - **-19.30991429**: The negative MSE for the first fold.\n",
        "   - **-18.63603471**: The negative MSE for the second fold.\n",
        "   - **-20.86669768**: The negative MSE for the third fold.\n",
        "   - **-21.72356501**: The negative MSE for the fourth fold.\n",
        "   - **-20.18491094**: The negative MSE for the fifth fold.\n",
        "\n",
        "3. **Mean Score:**\n",
        "   ```python\n",
        "   -20.144224523434428\n",
        "   ```\n",
        "   - This value represents the average negative mean squared error across all 5 folds.\n",
        "   - To interpret it in terms of actual MSE, you take the negative of this mean score: `20.144224523434428`.\n",
        "\n",
        "### Good or Bad?\n",
        "- **Magnitude of MSE**:\n",
        "  - The actual MSE values (after taking the negative) are quite large (around 20). Whether these scores are good or bad depends on the context of your problem and the scale of your target variable.\n",
        "  - For instance, if the target values in your dataset range from 0 to 100, an MSE of 20 might indicate a considerable error. However, if the target values range from 0 to 1000, an MSE of 20 might be acceptable.\n",
        "\n",
        "- **Consistency**:\n",
        "  - The MSE values across the folds are relatively consistent, ranging from approximately 18.6 to 21.7. This consistency indicates that the model's performance is stable across different subsets of the data.\n",
        "\n",
        "### Contextual Factors to Consider\n",
        "- **Target Variable Scale**: If your target variable (in `y_train_cleaned`) has a wide range, then the MSE might need to be evaluated in that context. For example, if the target values are in the thousands, an MSE around 20 might be quite good.\n",
        "- **Baseline Comparison**: Compare these results to a baseline model (like a simple mean predictor) to determine if your model provides a significant improvement.\n",
        "- **Domain Expertise**: Leverage domain knowledge to judge if the prediction errors are within an acceptable range for practical use.\n",
        "\n",
        "### Next Steps\n",
        "- **Model Tuning**: If the MSE is considered high, you might want to tune your model's hyperparameters further.\n",
        "- **Feature Engineering**: Consider improving the feature set by adding new features or removing less relevant ones.\n",
        "- **Different Models**: Try different models to see if they can achieve a lower MSE.\n",
        "\n",
        "By carefully analyzing the cross-validation scores in the context of your specific problem, you can better understand the model's performance and determine the next steps for improvement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7YQKxfZlIhz"
      },
      "source": [
        "We'll see later that many of the tools in sklearn use cross-fold validation internally, so you don't need to do the separate steps as above. However, it's good to know that this is what's going on behind the scenes.\n",
        "\n",
        "You can load, train and test other models in much the same way as MLPRegressor. They all have `fit()` and `predict()` functions, and can all be supplied to cross_val_score.\n",
        "\n",
        "Try comparing a few other model types. Browse the [documentation](https://scikit-learn.org/stable/supervised_learning.html) for regression models: don't worry specifically which you choose, as we've not given any detail on these yet, but `sklearn.linear_model.LinearRegression` and `sklearn.ensemble.RandomForestRegressor` are good places to start. Which one performs best on this data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bz8alpSolIhz",
        "outputId": "025a9703-539c-4539-960b-dca0c4caffed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-18.20392508 -15.55852264 -14.98403196 -17.90668237 -18.33371611]\n",
            "-16.997375632892886\n",
            "[-19.28467425 -18.59132314 -20.84440275 -21.72625717 -20.14640706]\n",
            "-20.11861287615306\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "m1 = RandomForestRegressor()\n",
        "m2 = LinearRegression()\n",
        "# ...\n",
        "\n",
        "scores = cross_val_score(m1, X_train_encoded, y_train_cleaned, cv=5, scoring='neg_mean_squared_error')\n",
        "print(scores)\n",
        "print(scores.mean())\n",
        "\n",
        "scores = cross_val_score(m2, X_train_encoded, y_train_cleaned, cv=5, scoring='neg_mean_squared_error')\n",
        "print(scores)\n",
        "print(scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOhUKjCLlIhz"
      },
      "source": [
        "Comment: Looks like the RandomForestRegressor is the best model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfuzAMOqlIhz"
      },
      "source": [
        "Finally, we retrain the model that did best in cross validation on all the training data (not just one fold) then apply the best model to the original, unseen test data.\n",
        "\n",
        "The test set will need the same column transformations applied, but we can choose whether any additional cleaning is needed (e.g. outliers can affect the training so we remove them there, but we might still want to see if the final model can cope with them). Here we don't do any cleaning on the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdScyriwlIhz",
        "outputId": "71b84f50-84b8-4bb9-84da-b515a8699ba7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15.571123727904327\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:227: UserWarning: Found unknown categories in columns [0, 1] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Put the best model you found here...\n",
        "final_model = RandomForestRegressor()\n",
        "final_model.fit(X_train_encoded, y_train_cleaned)\n",
        "\n",
        "X_test_transformed = col_transform.transform(X_test)\n",
        "\n",
        "y_pred = final_model.predict(X_test_transformed)\n",
        "\n",
        "# how do the predictions compare to the true values?\n",
        "# print mean square error\n",
        "from sklearn import metrics\n",
        "print(metrics.mean_squared_error(y_pred, y_test))\n",
        "\n",
        "# is this error better or worse than the scores you've seen above? Often it will be worse (a bigger value) because\n",
        "# the test data is unseen but sometimes, as is the case here, we'll be lucky and it'll be better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka3BHxjGlIh0"
      },
      "source": [
        "### Code Explanation\n",
        "\n",
        "```python\n",
        "# Put the best model you found here...\n",
        "final_model = RandomForestRegressor()\n",
        "```\n",
        "1. **Model Selection**:\n",
        "   - The `RandomForestRegressor` from the `sklearn.ensemble` module is chosen as the final model. This is an ensemble learning method that combines multiple decision trees to improve prediction accuracy and control overfitting.\n",
        "\n",
        "```python\n",
        "final_model.fit(X_train_encoded, y_train_cleaned)\n",
        "```\n",
        "2. **Model Training**:\n",
        "   - The `fit` method is used to train the `RandomForestRegressor` on the encoded training data (`X_train_encoded`) and the cleaned training targets (`y_train_cleaned`). This step builds the random forest model based on the provided data.\n",
        "\n",
        "```python\n",
        "X_test_transformed = col_transform.transform(X_test)\n",
        "```\n",
        "3. **Transforming Test Data**:\n",
        "   - The `ColumnTransformer` (`col_transform`) used earlier to encode the training data is now applied to the test data (`X_test`). This ensures that the test data undergoes the same preprocessing steps (e.g., one-hot encoding for categorical features and scaling for numerical features) as the training data.\n",
        "\n",
        "```python\n",
        "y_pred = final_model.predict(X_test_transformed)\n",
        "```\n",
        "4. **Model Prediction**:\n",
        "   - The trained `RandomForestRegressor` model is used to make predictions on the transformed test data (`X_test_transformed`). The predicted values are stored in `y_pred`.\n",
        "\n",
        "```python\n",
        "# how do the predictions compare to the true values?\n",
        "# print mean square error\n",
        "from sklearn import metrics\n",
        "print(metrics.mean_squared_error(y_pred, y_test))\n",
        "```\n",
        "5. **Evaluation**:\n",
        "   - The mean squared error (MSE) of the predictions is calculated using `metrics.mean_squared_error` from `sklearn`. This function compares the predicted values (`y_pred`) to the actual target values (`y_test`), which were not transformed.\n",
        "   - The MSE is a common metric for evaluating regression models. It measures the average squared difference between the predicted values and the actual values, indicating how close the predictions are to the true values. A lower MSE indicates better model performance.\n",
        "  \n",
        "### Detailed Example\n",
        "\n",
        "Let\"'\"s illustrate this with a simple example\n",
        "\n",
        "1. **Model Initialization and Training**:\n",
        "   ```python\n",
        "   from sklearn.ensemble import RandomForestRegressor\n",
        "   \n",
        "   # Initialize the model\n",
        "   final_model = RandomForestRegressor()\n",
        "   \n",
        "   # Fit the model on the training data\n",
        "   final_model.fit(X_train_encoded, y_train_cleaned)\n",
        "   ```\n",
        "   Here, the `RandomForestRegressor` is being trained on the encoded features and corresponding target values.\n",
        "2. **Transform Test Data**:\n",
        "   ```python\n",
        "   # Transform the test data using the same column transformer\n",
        "   X_test_transformed = col_transform.transform(X_test)\n",
        "   ```\n",
        "   This ensures that the test data is processed in the same way as the training data, maintaining consistency in the feature representation.\n",
        "\n",
        "3. **Model Prediction**:\n",
        "   ```python\n",
        "   # Predict on the transformed test data\n",
        "   y_pred = final_model.predict(X_test_transformed)\n",
        "   ```\n",
        "   The model uses the learned patterns to predict the target values for the test data.\n",
        "\n",
        "4. **Evaluate Model Performance**:\n",
        "   ```python\n",
        "   from sklearn import metrics\n",
        "   \n",
        "   # Calculate the mean squared error\n",
        "   mse = metrics.mean_squared_error(y_pred, y_test)\n",
        "   print(mse)\n",
        "   ```\n",
        "   The MSE is calculated to quantify the error between the predicted and actual values. This helps in assessing how well the model performs on unseen data.\n",
        "\n",
        "### Interpretation of MSE\n",
        "\n",
        "- **Good Model Performance**: If the MSE is low, it means that the model\"'\"s predictions are close to the actual values, indicating good performance.\n",
        "- **Poor Model Performance**: If the MSE is high, it suggests that there is a significant difference between the predicted and actual values, indicating that the model may not be performing well.\n",
        "\n",
        "To determine if the MSE value is good or bad, it should be compared to a baseline model or other models trained on the same data. Additionally, the scale of the target variable plays a crucial role in interpreting the MSE.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caJmUcdUlIh0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}